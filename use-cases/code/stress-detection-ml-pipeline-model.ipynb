{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIAO Automatic Modeling: Stress Detection Dataset\n",
    "\n",
    "This notebook demonstrates automatic generation of MIAO-compliant RDF annotations from:\n",
    "1. A text dataset with binary stress labels (0=no stress, 1=stress)\n",
    "2. Machine learning experiment results (model performance metrics)\n",
    "\n",
    "The notebook creates a complete RDF knowledge graph following the MIAO ontology structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (uncomment if needed)\n",
    "# !pip install rdflib pandas numpy scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from rdflib import Graph, Namespace, Literal, URIRef, RDF, RDFS, XSD\n",
    "from rdflib.namespace import DCTERMS, PROV\n",
    "import hashlib\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define Namespaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define MIAO and related namespaces\n",
    "MIAO = Namespace(\"https://w3id.org/miao#\")\n",
    "MLS = Namespace(\"http://www.w3.org/ns/mls#\")\n",
    "EX = Namespace(\"https://w3id.org/miao/experiment#\")\n",
    "\n",
    "# Create RDF graph\n",
    "g = Graph()\n",
    "g.bind(\"miao\", MIAO)\n",
    "g.bind(\"mls\", MLS)\n",
    "g.bind(\"ex\", EX)\n",
    "g.bind(\"dcterms\", DCTERMS)\n",
    "g.bind(\"prov\", PROV)\n",
    "g.bind(\"rdfs\", RDFS)\n",
    "g.bind(\"xsd\", XSD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Input Data\n",
    "\n",
    "### 3.1 Load Stress Detection Dataset\n",
    "\n",
    "Expected format:\n",
    "- CSV file with columns: `text`, `label`\n",
    "- `label`: 0 (no stress) or 1 (stress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5 samples\n",
      "Stress distribution: {1: 3, 0: 2}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm feeling overwhelmed with work deadlines an...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Had a great day at the beach, feeling relaxed ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Can't sleep at night, constant worry about fin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Enjoyed a peaceful morning walk in the park</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My anxiety is through the roof with upcoming e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  I'm feeling overwhelmed with work deadlines an...      1\n",
       "1  Had a great day at the beach, feeling relaxed ...      0\n",
       "2  Can't sleep at night, constant worry about fin...      1\n",
       "3        Enjoyed a peaceful morning walk in the park      0\n",
       "4  My anxiety is through the roof with upcoming e...      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset (replace with your actual file path)\n",
    "# For demonstration, we'll create a sample dataset\n",
    "\n",
    "# Option 1: Load from CSV\n",
    "# df_dataset = pd.read_csv('stress_dataset.csv')\n",
    "\n",
    "# Option 2: Create sample data for demonstration\n",
    "df_dataset = pd.DataFrame({\n",
    "    'text': [\n",
    "        \"I'm feeling overwhelmed with work deadlines and family responsibilities\",\n",
    "        \"Had a great day at the beach, feeling relaxed and happy\",\n",
    "        \"Can't sleep at night, constant worry about finances\",\n",
    "        \"Enjoyed a peaceful morning walk in the park\",\n",
    "        \"My anxiety is through the roof with upcoming exams\"\n",
    "    ],\n",
    "    'label': [1, 0, 1, 0, 1]  # 1=stress, 0=no stress\n",
    "})\n",
    "\n",
    "print(f\"Loaded {len(df_dataset)} samples\")\n",
    "print(f\"Stress distribution: {df_dataset['label'].value_counts().to_dict()}\")\n",
    "df_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Load ML Experiment Results\n",
    "\n",
    "Expected format:\n",
    "- DataFrame with columns: `sample_id`, `model_name`, `predicted_label`, `confidence`, `true_label`\n",
    "- Additional metadata: `experiment_date`, `hyperparameters`, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5 predictions\n",
      "Accuracy: 1.00\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>model_name</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>confidence</th>\n",
       "      <th>true_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>BERT_Stress_Classifier</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>BERT_Stress_Classifier</td>\n",
       "      <td>0</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>BERT_Stress_Classifier</td>\n",
       "      <td>1</td>\n",
       "      <td>0.78</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>BERT_Stress_Classifier</td>\n",
       "      <td>0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>BERT_Stress_Classifier</td>\n",
       "      <td>1</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sample_id              model_name  predicted_label  confidence  true_label\n",
       "0          0  BERT_Stress_Classifier                1        0.92           1\n",
       "1          1  BERT_Stress_Classifier                0        0.87           0\n",
       "2          2  BERT_Stress_Classifier                1        0.78           1\n",
       "3          3  BERT_Stress_Classifier                0        0.95           0\n",
       "4          4  BERT_Stress_Classifier                1        0.84           1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Option 1: Load from CSV\n",
    "# df_results = pd.read_csv('experiment_results.csv')\n",
    "\n",
    "# Option 2: Create sample results for demonstration\n",
    "df_results = pd.DataFrame({\n",
    "    'sample_id': [0, 1, 2, 3, 4],\n",
    "    'model_name': ['BERT_Stress_Classifier', 'BERT_Stress_Classifier', \n",
    "                   'BERT_Stress_Classifier', 'BERT_Stress_Classifier', \n",
    "                   'BERT_Stress_Classifier'],\n",
    "    'predicted_label': [1, 0, 1, 0, 1],\n",
    "    'confidence': [0.92, 0.87, 0.78, 0.95, 0.84],\n",
    "    'true_label': [1, 0, 1, 0, 1]\n",
    "})\n",
    "\n",
    "# Model performance metrics (aggregate)\n",
    "model_metrics = {\n",
    "    'model_name': 'BERT_Stress_Classifier',\n",
    "    'implementation': 'PyTorch',\n",
    "    'version': '1.0',\n",
    "    'accuracy': 0.85,\n",
    "    'precision': 0.83,\n",
    "    'recall': 0.88,\n",
    "    'f1_score': 0.85,\n",
    "    'training_date': '2025-11-15',\n",
    "    'hyperparameters': {\n",
    "        'learning_rate': 2e-5,\n",
    "        'batch_size': 32,\n",
    "        'epochs': 10\n",
    "    }\n",
    "}\n",
    "\n",
    "print(f\"Loaded {len(df_results)} predictions\")\n",
    "print(f\"Accuracy: {(df_results['predicted_label'] == df_results['true_label']).mean():.2f}\")\n",
    "df_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create MIAO Schema and Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created schema: https://w3id.org/miao/experiment#StressSchema_Binary\n",
      "Categories: {0: rdflib.term.URIRef('https://w3id.org/miao/experiment#Stress_Negative'), 1: rdflib.term.URIRef('https://w3id.org/miao/experiment#Stress_Positive')}\n"
     ]
    }
   ],
   "source": [
    "def create_stress_schema(graph):\n",
    "    \"\"\"\n",
    "    Create binary stress classification schema in MIAO format.\n",
    "    \"\"\"\n",
    "    # Define schema\n",
    "    schema_uri = EX.StressSchema_Binary\n",
    "    graph.add((schema_uri, RDF.type, MIAO.MentalIllnessesSchema))\n",
    "    graph.add((schema_uri, DCTERMS.title, \n",
    "               Literal(\"Binary Stress Classification Schema\", lang=\"en\")))\n",
    "    graph.add((schema_uri, DCTERMS.description, \n",
    "               Literal(\"Binary schema for computational stress detection from text\", lang=\"en\")))\n",
    "    graph.add((schema_uri, DCTERMS.created, \n",
    "               Literal(datetime.now().strftime(\"%Y-%m-%d\"), datatype=XSD.date)))\n",
    "    \n",
    "    # Define categories\n",
    "    # Category 0: No Stress\n",
    "    no_stress_uri = EX.Stress_Negative\n",
    "    graph.add((no_stress_uri, RDF.type, MIAO.MentalIllnessCategory))\n",
    "    graph.add((no_stress_uri, DCTERMS.title, Literal(\"No Stress\", lang=\"en\")))\n",
    "    graph.add((no_stress_uri, DCTERMS.description, \n",
    "               Literal(\"No psychological stress indicators detected\", lang=\"en\")))\n",
    "    graph.add((no_stress_uri, MIAO.isMentalIllnessCategoryOf, schema_uri))\n",
    "    graph.add((schema_uri, MIAO.hasMentalIllnessCategory, no_stress_uri))\n",
    "    \n",
    "    # Category 1: Stress\n",
    "    stress_uri = EX.Stress_Positive\n",
    "    graph.add((stress_uri, RDF.type, MIAO.MentalIllnessCategory))\n",
    "    graph.add((stress_uri, DCTERMS.title, Literal(\"Stress\", lang=\"en\")))\n",
    "    graph.add((stress_uri, DCTERMS.description, \n",
    "               Literal(\"Psychological stress indicators detected\", lang=\"en\")))\n",
    "    graph.add((stress_uri, MIAO.isMentalIllnessCategoryOf, schema_uri))\n",
    "    graph.add((schema_uri, MIAO.hasMentalIllnessCategory, stress_uri))\n",
    "    \n",
    "    return schema_uri, {0: no_stress_uri, 1: stress_uri}\n",
    "\n",
    "schema_uri, category_map = create_stress_schema(g)\n",
    "print(f\"Created schema: {schema_uri}\")\n",
    "print(f\"Categories: {category_map}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Dataset as MIAO Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dataset: https://w3id.org/miao/experiment#StressTextDataset\n"
     ]
    }
   ],
   "source": [
    "def create_dataset_metadata(graph, df, dataset_name=\"StressTextDataset\"):\n",
    "    \"\"\"\n",
    "    Create dataset metadata in MLS format.\n",
    "    \"\"\"\n",
    "    dataset_uri = EX[dataset_name]\n",
    "    graph.add((dataset_uri, RDF.type, MLS.Dataset))\n",
    "    graph.add((dataset_uri, RDFS.label, \n",
    "               Literal(f\"{dataset_name} - Text samples for stress detection\", lang=\"en\")))\n",
    "    graph.add((dataset_uri, DCTERMS.description, \n",
    "               Literal(f\"Dataset containing {len(df)} text samples with binary stress annotations\", lang=\"en\")))\n",
    "    graph.add((dataset_uri, DCTERMS.extent, \n",
    "               Literal(f\"{len(df)} samples\", lang=\"en\")))\n",
    "    graph.add((dataset_uri, DCTERMS.format, Literal(\"text/plain\")))\n",
    "    graph.add((dataset_uri, DCTERMS.created, \n",
    "               Literal(datetime.now().strftime(\"%Y-%m-%dT%H:%M:%S\"), datatype=XSD.dateTime)))\n",
    "    \n",
    "    # Add statistics\n",
    "    stress_count = (df['label'] == 1).sum()\n",
    "    no_stress_count = (df['label'] == 0).sum()\n",
    "    graph.add((dataset_uri, EX.stressCount, Literal(int(stress_count), datatype=XSD.integer)))\n",
    "    graph.add((dataset_uri, EX.noStressCount, Literal(int(no_stress_count), datatype=XSD.integer)))\n",
    "    \n",
    "    return dataset_uri\n",
    "\n",
    "dataset_uri = create_dataset_metadata(g, df_dataset)\n",
    "print(f\"Created dataset: {dataset_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model ML Pipeline and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created implementation: https://w3id.org/miao/experiment#BERT_Stress_Classifier_Implementation\n",
      "Created model: https://w3id.org/miao/experiment#BERT_Stress_Classifier_v1.0\n"
     ]
    }
   ],
   "source": [
    "def create_ml_implementation(graph, model_metrics):\n",
    "    \"\"\"\n",
    "    Create ML implementation and software metadata.\n",
    "    \"\"\"\n",
    "    # Software (PyTorch)\n",
    "    software_uri = EX.PyTorch\n",
    "    graph.add((software_uri, RDF.type, MLS.Software))\n",
    "    graph.add((software_uri, RDFS.label, Literal(\"PyTorch\", lang=\"en\")))\n",
    "    graph.add((software_uri, DCTERMS.description, \n",
    "               Literal(\"Open-source machine learning framework\", lang=\"en\")))\n",
    "    \n",
    "    # Implementation\n",
    "    impl_name = model_metrics['model_name'].replace(' ', '_')\n",
    "    impl_uri = EX[f\"{impl_name}_Implementation\"]\n",
    "    graph.add((impl_uri, RDF.type, MLS.Implementation))\n",
    "    graph.add((impl_uri, RDFS.label, \n",
    "               Literal(f\"{model_metrics['model_name']} Implementation\", lang=\"en\")))\n",
    "    graph.add((impl_uri, DCTERMS.description, \n",
    "               Literal(\"BERT-based classifier fine-tuned for stress detection\", lang=\"en\")))\n",
    "    graph.add((software_uri, MLS.hasPart, impl_uri))\n",
    "    \n",
    "    # Hyperparameters\n",
    "    for param_name, param_value in model_metrics['hyperparameters'].items():\n",
    "        param_uri = EX[f\"{impl_name}_{param_name}\"]\n",
    "        graph.add((param_uri, RDF.type, MLS.HyperParameter))\n",
    "        graph.add((param_uri, RDFS.label, Literal(param_name.replace('_', ' ').title(), lang=\"en\")))\n",
    "        \n",
    "        # Determine datatype\n",
    "        if isinstance(param_value, float):\n",
    "            graph.add((param_uri, MLS.hasValue, Literal(param_value, datatype=XSD.float)))\n",
    "        elif isinstance(param_value, int):\n",
    "            graph.add((param_uri, MLS.hasValue, Literal(param_value, datatype=XSD.integer)))\n",
    "        else:\n",
    "            graph.add((param_uri, MLS.hasValue, Literal(str(param_value))))\n",
    "        \n",
    "        graph.add((impl_uri, MLS.hasHyperParameter, param_uri))\n",
    "    \n",
    "    return impl_uri\n",
    "\n",
    "def create_trained_model(graph, model_metrics, impl_uri):\n",
    "    \"\"\"\n",
    "    Create trained model instance.\n",
    "    \"\"\"\n",
    "    model_name = model_metrics['model_name'].replace(' ', '_')\n",
    "    model_uri = EX[f\"{model_name}_v{model_metrics['version']}\"]\n",
    "    graph.add((model_uri, RDF.type, MLS.Model))\n",
    "    graph.add((model_uri, RDFS.label, \n",
    "               Literal(f\"{model_metrics['model_name']} v{model_metrics['version']}\", lang=\"en\")))\n",
    "    graph.add((model_uri, DCTERMS.created, \n",
    "               Literal(model_metrics['training_date'], datatype=XSD.date)))\n",
    "    graph.add((model_uri, DCTERMS.description, \n",
    "               Literal(\"Trained BERT model for binary stress classification\", lang=\"en\")))\n",
    "    \n",
    "    return model_uri\n",
    "\n",
    "impl_uri = create_ml_implementation(g, model_metrics)\n",
    "model_uri = create_trained_model(g, model_metrics, impl_uri)\n",
    "print(f\"Created implementation: {impl_uri}\")\n",
    "print(f\"Created model: {model_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Detection Run and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created detection run: https://w3id.org/miao/experiment#Run_4b34daf2\n"
     ]
    }
   ],
   "source": [
    "def create_detection_run(graph, schema_uri, dataset_uri, impl_uri, model_uri, model_metrics):\n",
    "    \"\"\"\n",
    "    Create automatic detection run (experiment execution).\n",
    "    \"\"\"\n",
    "    run_id = hashlib.md5(f\"{model_metrics['model_name']}_{datetime.now()}\".encode()).hexdigest()[:8]\n",
    "    run_uri = EX[f\"Run_{run_id}\"]\n",
    "    \n",
    "    graph.add((run_uri, RDF.type, MIAO.AutomaticMentalIllnessesDetection))\n",
    "    graph.add((run_uri, RDF.type, MLS.Run))\n",
    "    graph.add((run_uri, RDFS.label, \n",
    "               Literal(f\"Stress detection run {run_id}\", lang=\"en\")))\n",
    "    graph.add((run_uri, DCTERMS.description, \n",
    "               Literal(\"Automatic stress detection from text using BERT classifier\", lang=\"en\")))\n",
    "    graph.add((run_uri, DCTERMS.created, \n",
    "               Literal(datetime.now().strftime(\"%Y-%m-%dT%H:%M:%S\"), datatype=XSD.dateTime)))\n",
    "    \n",
    "    # Connect to components\n",
    "    graph.add((run_uri, MIAO.hasInputData, dataset_uri))\n",
    "    graph.add((run_uri, MIAO.usedMentalIllnessesSchema, schema_uri))\n",
    "    graph.add((run_uri, MLS.executes, impl_uri))\n",
    "    \n",
    "    # Create evaluation measures\n",
    "    metrics = ['accuracy', 'precision', 'recall', 'f1_score']\n",
    "    for metric in metrics:\n",
    "        measure_uri = EX[metric]\n",
    "        graph.add((measure_uri, RDF.type, MLS.EvaluationMeasure))\n",
    "        graph.add((measure_uri, RDFS.label, Literal(metric.replace('_', ' ').title(), lang=\"en\")))\n",
    "        \n",
    "        eval_uri = EX[f\"{run_id}_{metric}_evaluation\"]\n",
    "        graph.add((eval_uri, RDF.type, MLS.ModelEvaluation))\n",
    "        graph.add((eval_uri, MLS.specifiedBy, measure_uri))\n",
    "        graph.add((eval_uri, MLS.hasValue, Literal(model_metrics[metric], datatype=XSD.float)))\n",
    "        graph.add((run_uri, MLS.hasOutput, eval_uri))\n",
    "    \n",
    "    graph.add((run_uri, MLS.hasOutput, model_uri))\n",
    "    \n",
    "    return run_uri, run_id\n",
    "\n",
    "run_uri, run_id = create_detection_run(g, schema_uri, dataset_uri, impl_uri, model_uri, model_metrics)\n",
    "print(f\"Created detection run: {run_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model Individual Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 5 predictions in set: https://w3id.org/miao/experiment#StressSet_4b34daf2\n"
     ]
    }
   ],
   "source": [
    "def create_predictions(graph, df_results, df_dataset, run_uri, run_id, category_map):\n",
    "    \"\"\"\n",
    "    Create individual mental illness predictions for each sample.\n",
    "    \"\"\"\n",
    "    # Create mental illness set\n",
    "    illness_set_uri = EX[f\"StressSet_{run_id}\"]\n",
    "    graph.add((illness_set_uri, RDF.type, MIAO.MentalIllnessesSet))\n",
    "    graph.add((illness_set_uri, RDFS.label, \n",
    "               Literal(f\"Stress detection results from run {run_id}\", lang=\"en\")))\n",
    "    graph.add((illness_set_uri, PROV.wasGeneratedBy, run_uri))\n",
    "    graph.add((run_uri, PROV.generated, illness_set_uri))\n",
    "    \n",
    "    # Define Stress subclass\n",
    "    stress_class = EX.Stress\n",
    "    graph.add((stress_class, RDFS.subClassOf, MIAO.MentalIllness))\n",
    "    graph.add((stress_class, RDFS.label, Literal(\"Stress\", lang=\"en\")))\n",
    "    \n",
    "    # Create individual predictions\n",
    "    for idx, row in df_results.iterrows():\n",
    "        sample_id = row['sample_id']\n",
    "        predicted_label = row['predicted_label']\n",
    "        confidence = row['confidence']\n",
    "        \n",
    "        # Create illness instance\n",
    "        illness_uri = EX[f\"Stress_{run_id}_sample_{sample_id}\"]\n",
    "        graph.add((illness_uri, RDF.type, stress_class))\n",
    "        graph.add((illness_uri, MIAO.belongsToMentalIllnessesSet, illness_set_uri))\n",
    "        graph.add((illness_set_uri, MIAO.hasMentalIllness, illness_uri))\n",
    "        \n",
    "        # Add category reference\n",
    "        category_uri = category_map[predicted_label]\n",
    "        graph.add((illness_uri, MIAO.referredToMentalIllnessCategory, category_uri))\n",
    "        \n",
    "        # Add confidence\n",
    "        graph.add((illness_uri, MIAO.hasMentalIllnessDetectionConfidence, \n",
    "                   Literal(float(confidence), datatype=XSD.decimal)))\n",
    "        \n",
    "        # Add sample reference\n",
    "        sample_ref = f\"text_sample_{sample_id}\"\n",
    "        graph.add((illness_uri, MIAO.refersToSample, Literal(sample_ref, datatype=XSD.string)))\n",
    "        \n",
    "        # Add label and description\n",
    "        label_text = \"Stress\" if predicted_label == 1 else \"No Stress\"\n",
    "        graph.add((illness_uri, RDFS.label, \n",
    "                   Literal(f\"{label_text} prediction for sample {sample_id}\", lang=\"en\")))\n",
    "        \n",
    "        # Optional: add text snippet (first 100 chars)\n",
    "        if sample_id < len(df_dataset):\n",
    "            text_snippet = df_dataset.iloc[sample_id]['text'][:100]\n",
    "            graph.add((illness_uri, DCTERMS.description, \n",
    "                       Literal(f\"Prediction for text: '{text_snippet}...'\", lang=\"en\")))\n",
    "    \n",
    "    return illness_set_uri\n",
    "\n",
    "illness_set_uri = create_predictions(g, df_results, df_dataset, run_uri, run_id, category_map)\n",
    "print(f\"Created {len(df_results)} predictions in set: {illness_set_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Export RDF Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "RDF GRAPH STATISTICS\n",
      "==================================================\n",
      "Total triples: 124\n",
      "\n",
      "Triples by type:\n",
      "  Stress: 5\n",
      "  EvaluationMeasure: 4\n",
      "  ModelEvaluation: 4\n",
      "  HyperParameter: 3\n",
      "  MentalIllnessCategory: 2\n",
      "  MentalIllnessesSchema: 1\n",
      "  Dataset: 1\n",
      "  Software: 1\n",
      "  Implementation: 1\n",
      "  Model: 1\n",
      "  AutomaticMentalIllnessesDetection: 1\n",
      "  Run: 1\n",
      "  MentalIllnessesSet: 1\n"
     ]
    }
   ],
   "source": [
    "# Print statistics\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"RDF GRAPH STATISTICS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Total triples: {len(g)}\")\n",
    "print(f\"\\nTriples by type:\")\n",
    "\n",
    "# Count by type\n",
    "type_counts = {}\n",
    "for s, p, o in g.triples((None, RDF.type, None)):\n",
    "    obj_str = str(o).split('#')[-1].split('/')[-1]\n",
    "    type_counts[obj_str] = type_counts.get(obj_str, 0) + 1\n",
    "\n",
    "for type_name, count in sorted(type_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"  {type_name}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RDF graph exported to: stress_detection_experiment.ttl\n",
      "File size: 6747 bytes\n"
     ]
    }
   ],
   "source": [
    "# Export to Turtle format\n",
    "output_file = \"stress_detection_experiment.ttl\"\n",
    "g.serialize(destination=output_file, format=\"turtle\")\n",
    "print(f\"\\nRDF graph exported to: {output_file}\")\n",
    "print(f\"File size: {len(g.serialize(format='turtle'))} bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Sample SPARQL Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1: High-confidence predictions (> 0.8)\n",
      "==================================================\n",
      "Sample: text_sample_3, Confidence: 0.95, Category: Stress_Negative\n",
      "Sample: text_sample_0, Confidence: 0.92, Category: Stress_Positive\n",
      "Sample: text_sample_1, Confidence: 0.87, Category: Stress_Negative\n",
      "Sample: text_sample_4, Confidence: 0.84, Category: Stress_Positive\n",
      "\n",
      "Total: 4 predictions\n"
     ]
    }
   ],
   "source": [
    "# Query 1: Get all predictions with confidence > 0.8\n",
    "query1 = \"\"\"\n",
    "PREFIX miao: <https://w3id.org/miao#>\n",
    "PREFIX ex: <https://w3id.org/miao/experiment#>\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "\n",
    "SELECT ?illness ?label ?category ?confidence ?sample\n",
    "WHERE {\n",
    "  ?illness a ex:Stress ;\n",
    "           rdfs:label ?label ;\n",
    "           miao:referredToMentalIllnessCategory ?category ;\n",
    "           miao:hasMentalIllnessDetectionConfidence ?confidence ;\n",
    "           miao:refersToSample ?sample .\n",
    "  FILTER(?confidence > 0.8)\n",
    "}\n",
    "ORDER BY DESC(?confidence)\n",
    "\"\"\"\n",
    "\n",
    "print(\"Query 1: High-confidence predictions (> 0.8)\")\n",
    "print(\"=\"*50)\n",
    "results = g.query(query1)\n",
    "for row in results:\n",
    "    print(f\"Sample: {row.sample}, Confidence: {row.confidence}, Category: {str(row.category).split('#')[-1]}\")\n",
    "print(f\"\\nTotal: {len(results)} predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query 2: Model Performance Metrics\n",
      "==================================================\n",
      "Accuracy: 0.850\n",
      "F1 Score: 0.850\n",
      "Precision: 0.830\n",
      "Recall: 0.880\n"
     ]
    }
   ],
   "source": [
    "# Query 2: Get model performance metrics\n",
    "query2 = \"\"\"\n",
    "PREFIX mls: <http://www.w3.org/ns/mls#>\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "\n",
    "SELECT ?metric ?value\n",
    "WHERE {\n",
    "  ?evaluation a mls:ModelEvaluation ;\n",
    "              mls:specifiedBy ?measure ;\n",
    "              mls:hasValue ?value .\n",
    "  ?measure rdfs:label ?metric .\n",
    "}\n",
    "ORDER BY ?metric\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\nQuery 2: Model Performance Metrics\")\n",
    "print(\"=\"*50)\n",
    "results = g.query(query2)\n",
    "for row in results:\n",
    "    print(f\"{row.metric}: {float(row.value):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query 3: Prediction Distribution\n",
      "==================================================\n",
      "Stress: <built-in method count of ResultRow object at 0x745ff7dd6bb0> predictions\n",
      "No Stress: <built-in method count of ResultRow object at 0x745ff7dd6750> predictions\n"
     ]
    }
   ],
   "source": [
    "# Query 3: Count predictions by category\n",
    "query3 = \"\"\"\n",
    "PREFIX miao: <https://w3id.org/miao#>\n",
    "PREFIX dcterms: <http://purl.org/dc/terms/>\n",
    "\n",
    "SELECT ?categoryTitle (COUNT(?illness) as ?count)\n",
    "WHERE {\n",
    "  ?illness miao:referredToMentalIllnessCategory ?category .\n",
    "  ?category dcterms:title ?categoryTitle .\n",
    "}\n",
    "GROUP BY ?categoryTitle\n",
    "ORDER BY DESC(?count)\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\nQuery 3: Prediction Distribution\")\n",
    "print(\"=\"*50)\n",
    "results = g.query(query3)\n",
    "for row in results:\n",
    "    print(f\"{row.categoryTitle}: {row.count} predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Validation Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "MIAO MODELING VALIDATION REPORT\n",
      "======================================================================\n",
      "[PASS] Mental Illness Schema: 1/1\n",
      "[PASS] Mental Illness Categories: 2/2\n",
      "[PASS] Dataset: 1/1\n",
      "[PASS] ML Implementation: 1/1\n",
      "[PASS] Trained Model: 1/1\n",
      "[PASS] Detection Run: 1/1\n",
      "[PASS] Mental Illness Set: 1/1\n",
      "[PASS] Individual Predictions: 5/5\n",
      "[PASS] Model Evaluations: 4/4\n",
      "\n",
      "======================================================================\n",
      "VALIDATION PASSED: All MIAO components correctly modeled\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Generate validation report\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MIAO MODELING VALIDATION REPORT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Check required components\n",
    "checks = [\n",
    "    (\"Mental Illness Schema\", len(list(g.triples((None, RDF.type, MIAO.MentalIllnessesSchema)))), 1),\n",
    "    (\"Mental Illness Categories\", len(list(g.triples((None, RDF.type, MIAO.MentalIllnessCategory)))), 2),\n",
    "    (\"Dataset\", len(list(g.triples((None, RDF.type, MLS.Dataset)))), 1),\n",
    "    (\"ML Implementation\", len(list(g.triples((None, RDF.type, MLS.Implementation)))), 1),\n",
    "    (\"Trained Model\", len(list(g.triples((None, RDF.type, MLS.Model)))), 1),\n",
    "    (\"Detection Run\", len(list(g.triples((None, RDF.type, MIAO.AutomaticMentalIllnessesDetection)))), 1),\n",
    "    (\"Mental Illness Set\", len(list(g.triples((None, RDF.type, MIAO.MentalIllnessesSet)))), 1),\n",
    "    (\"Individual Predictions\", len(list(g.triples((None, MIAO.hasMentalIllnessDetectionConfidence, None)))), len(df_results)),\n",
    "    (\"Model Evaluations\", len(list(g.triples((None, RDF.type, MLS.ModelEvaluation)))), 4),\n",
    "]\n",
    "\n",
    "all_passed = True\n",
    "for component, actual, expected in checks:\n",
    "    status = \"PASS\" if actual >= expected else \"FAIL\"\n",
    "    if status == \"FAIL\":\n",
    "        all_passed = False\n",
    "    print(f\"[{status}] {component}: {actual}/{expected}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "if all_passed:\n",
    "    print(\"VALIDATION PASSED: All MIAO components correctly modeled\")\n",
    "else:\n",
    "    print(\"VALIDATION FAILED: Some components are missing or incomplete\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
