{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MIAO Automatic Modeling: Depression Severity Detection\n",
        "\n",
        "This notebook demonstrates automatic generation of MIAO-compliant RDF annotations from:\n",
        "1. A text dataset with ordinal depression severity labels (0=Minimal, 1=Mild, 2=Moderate, 3=Severe)\n",
        "2. Machine learning experiment results from multiple models (BERT, Feature Framework)\n",
        "\n",
        "The notebook creates a complete RDF knowledge graph following the MIAO ontology structure for depression severity research, including:\n",
        "- Proper schema alignment with PHQ-9 standards\n",
        "- SKOS mappings to SNOMED CT clinical terminology\n",
        "- Bibliographic citations and provenance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages (uncomment if needed)\n",
        "# !pip install rdflib pandas numpy scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from rdflib import Graph, Namespace, Literal, URIRef, RDF, RDFS, XSD\n",
        "from rdflib.namespace import DCTERMS, PROV, SKOS, OWL\n",
        "import hashlib\n",
        "import json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Define Namespaces\n",
        "\n",
        "Define all required namespaces including SKOS for concept mappings and external medical ontologies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RDF graph initialized with namespaces:\n",
            "  brick: https://brickschema.org/schema/Brick#\n",
            "  csvw: http://www.w3.org/ns/csvw#\n",
            "  dc: http://purl.org/dc/elements/1.1/\n",
            "  dcat: http://www.w3.org/ns/dcat#\n",
            "  dcmitype: http://purl.org/dc/dcmitype/\n",
            "  dcterms: http://purl.org/dc/terms/\n",
            "  dcam: http://purl.org/dc/dcam/\n",
            "  doap: http://usefulinc.com/ns/doap#\n",
            "  foaf: http://xmlns.com/foaf/0.1/\n",
            "  geo: http://www.opengis.net/ont/geosparql#\n",
            "  odrl: http://www.w3.org/ns/odrl/2/\n",
            "  org: http://www.w3.org/ns/org#\n",
            "  prof: http://www.w3.org/ns/dx/prof/\n",
            "  prov: http://www.w3.org/ns/prov#\n",
            "  qb: http://purl.org/linked-data/cube#\n",
            "  schema: https://schema.org/\n",
            "  sh: http://www.w3.org/ns/shacl#\n",
            "  skos: http://www.w3.org/2004/02/skos/core#\n",
            "  sosa: http://www.w3.org/ns/sosa/\n",
            "  ssn: http://www.w3.org/ns/ssn/\n",
            "  time: http://www.w3.org/2006/time#\n",
            "  vann: http://purl.org/vocab/vann/\n",
            "  void: http://rdfs.org/ns/void#\n",
            "  wgs: https://www.w3.org/2003/01/geo/wgs84_pos#\n",
            "  owl: http://www.w3.org/2002/07/owl#\n",
            "  rdf: http://www.w3.org/1999/02/22-rdf-syntax-ns#\n",
            "  rdfs: http://www.w3.org/2000/01/rdf-schema#\n",
            "  xsd: http://www.w3.org/2001/XMLSchema#\n",
            "  xml: http://www.w3.org/XML/1998/namespace\n",
            "  miao: https://w3id.org/miao#\n",
            "  mls: http://www.w3.org/ns/mls#\n",
            "  ex: http://example.org/miao/\n",
            "  snomed: http://snomed.info/id/\n",
            "  icd11: http://id.who.int/icd/entity/\n"
          ]
        }
      ],
      "source": [
        "# Define MIAO and related namespaces\n",
        "MIAO = Namespace(\"https://w3id.org/miao#\")\n",
        "MLS = Namespace(\"http://www.w3.org/ns/mls#\")\n",
        "EX = Namespace(\"http://example.org/miao/\")\n",
        "\n",
        "# External medical ontologies\n",
        "SNOMED = Namespace(\"http://snomed.info/id/\")\n",
        "ICD11 = Namespace(\"http://id.who.int/icd/entity/\")\n",
        "\n",
        "# Create RDF graph\n",
        "g = Graph()\n",
        "g.bind(\"miao\", MIAO)\n",
        "g.bind(\"mls\", MLS)\n",
        "g.bind(\"ex\", EX)\n",
        "g.bind(\"dcterms\", DCTERMS)\n",
        "g.bind(\"prov\", PROV)\n",
        "g.bind(\"rdfs\", RDFS)\n",
        "g.bind(\"xsd\", XSD)\n",
        "g.bind(\"skos\", SKOS)\n",
        "g.bind(\"owl\", OWL)\n",
        "g.bind(\"snomed\", SNOMED)\n",
        "g.bind(\"icd11\", ICD11)\n",
        "\n",
        "print(\"RDF graph initialized with namespaces:\")\n",
        "for prefix, namespace in g.namespaces():\n",
        "    print(f\"  {prefix}: {namespace}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Load Input Data\n",
        "\n",
        "### 3.1 Load Depression Severity Dataset\n",
        "\n",
        "Expected format:\n",
        "- CSV file with columns: `text`, `severity_label`\n",
        "- `severity_label`: 0 (Minimal), 1 (Mild), 2 (Moderate), 3 (Severe)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 10 samples\n",
            "\n",
            "Severity distribution:\n",
            "severity_name\n",
            "Minimal     3\n",
            "Moderate    3\n",
            "Mild        2\n",
            "Severe      2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "First 5 samples:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>severity_label</th>\n",
              "      <th>severity_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Feeling okay today, nothing special but managi...</td>\n",
              "      <td>0</td>\n",
              "      <td>Minimal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sometimes I feel a bit down but it passes quickly</td>\n",
              "      <td>1</td>\n",
              "      <td>Mild</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Having trouble getting out of bed, everything ...</td>\n",
              "      <td>2</td>\n",
              "      <td>Moderate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I can't remember the last time I felt happy, c...</td>\n",
              "      <td>3</td>\n",
              "      <td>Severe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Life is good, enjoying my hobbies and social a...</td>\n",
              "      <td>0</td>\n",
              "      <td>Minimal</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  severity_label  \\\n",
              "0  Feeling okay today, nothing special but managi...               0   \n",
              "1  Sometimes I feel a bit down but it passes quickly               1   \n",
              "2  Having trouble getting out of bed, everything ...               2   \n",
              "3  I can't remember the last time I felt happy, c...               3   \n",
              "4  Life is good, enjoying my hobbies and social a...               0   \n",
              "\n",
              "  severity_name  \n",
              "0       Minimal  \n",
              "1          Mild  \n",
              "2      Moderate  \n",
              "3        Severe  \n",
              "4       Minimal  "
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load dataset (replace with your actual file path)\n",
        "# df_dataset = pd.read_csv('depression_dataset.csv')\n",
        "\n",
        "# For demonstration, create sample data\n",
        "df_dataset = pd.DataFrame({\n",
        "    'text': [\n",
        "        'Feeling okay today, nothing special but managing fine',\n",
        "        'Sometimes I feel a bit down but it passes quickly',\n",
        "        'Having trouble getting out of bed, everything feels heavy',\n",
        "        \"I can't remember the last time I felt happy, constant despair\",\n",
        "        'Life is good, enjoying my hobbies and social activities',\n",
        "        'Feel slightly sad occasionally but cope well overall',\n",
        "        'Struggling to concentrate, lost interest in most things',\n",
        "        'Complete hopelessness, thoughts of ending it all',\n",
        "        'Pretty content with life, normal ups and downs',\n",
        "        'Persistent sadness affecting work and relationships'\n",
        "    ],\n",
        "    'severity_label': [0, 1, 2, 3, 0, 1, 2, 3, 0, 2]\n",
        "})\n",
        "\n",
        "# Map numeric labels to severity names\n",
        "severity_names = {0: 'Minimal', 1: 'Mild', 2: 'Moderate', 3: 'Severe'}\n",
        "df_dataset['severity_name'] = df_dataset['severity_label'].map(severity_names)\n",
        "\n",
        "print(f\"Loaded {len(df_dataset)} samples\\n\")\n",
        "print(\"Severity distribution:\")\n",
        "print(df_dataset['severity_name'].value_counts())\n",
        "print(\"\\nFirst 5 samples:\")\n",
        "df_dataset.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2 Load ML Experiment Results\n",
        "\n",
        "Expected format:\n",
        "- `sample_id`: integer index\n",
        "- `model_name`: name of the model\n",
        "- `predicted_label`: 0-3 (severity level)\n",
        "- `confidence`: prediction confidence (0-1)\n",
        "- `true_label`: ground truth label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 20 prediction results\n",
            "\n",
            "Results by model:\n",
            "model_name\n",
            "BERT_Depression_Classifier    10\n",
            "Feature_Framework_Model       10\n",
            "dtype: int64\n",
            "\n",
            "First 10 results:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sample_id</th>\n",
              "      <th>model_name</th>\n",
              "      <th>predicted_label</th>\n",
              "      <th>confidence</th>\n",
              "      <th>true_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>BERT_Depression_Classifier</td>\n",
              "      <td>0</td>\n",
              "      <td>0.94</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>BERT_Depression_Classifier</td>\n",
              "      <td>1</td>\n",
              "      <td>0.85</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>BERT_Depression_Classifier</td>\n",
              "      <td>2</td>\n",
              "      <td>0.74</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>BERT_Depression_Classifier</td>\n",
              "      <td>0</td>\n",
              "      <td>0.62</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>BERT_Depression_Classifier</td>\n",
              "      <td>0</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>BERT_Depression_Classifier</td>\n",
              "      <td>1</td>\n",
              "      <td>0.91</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>BERT_Depression_Classifier</td>\n",
              "      <td>2</td>\n",
              "      <td>0.75</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>BERT_Depression_Classifier</td>\n",
              "      <td>3</td>\n",
              "      <td>0.78</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>BERT_Depression_Classifier</td>\n",
              "      <td>0</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>BERT_Depression_Classifier</td>\n",
              "      <td>2</td>\n",
              "      <td>0.85</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sample_id                  model_name  predicted_label  confidence  \\\n",
              "0          0  BERT_Depression_Classifier                0        0.94   \n",
              "1          1  BERT_Depression_Classifier                1        0.85   \n",
              "2          2  BERT_Depression_Classifier                2        0.74   \n",
              "3          3  BERT_Depression_Classifier                0        0.62   \n",
              "4          4  BERT_Depression_Classifier                0        0.71   \n",
              "5          5  BERT_Depression_Classifier                1        0.91   \n",
              "6          6  BERT_Depression_Classifier                2        0.75   \n",
              "7          7  BERT_Depression_Classifier                3        0.78   \n",
              "8          8  BERT_Depression_Classifier                0        0.81   \n",
              "9          9  BERT_Depression_Classifier                2        0.85   \n",
              "\n",
              "   true_label  \n",
              "0           0  \n",
              "1           1  \n",
              "2           2  \n",
              "3           3  \n",
              "4           0  \n",
              "5           1  \n",
              "6           2  \n",
              "7           3  \n",
              "8           0  \n",
              "9           2  "
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Option 1: Load from CSV\n",
        "# df_results = pd.read_csv('model_results.csv')\n",
        "\n",
        "# Option 2: Create sample results for demonstration\n",
        "np.random.seed(42)\n",
        "results_data = []\n",
        "\n",
        "for model_name in ['BERT_Depression_Classifier', 'Feature_Framework_Model']:\n",
        "    for idx, row in df_dataset.iterrows():\n",
        "        true_label = row['severity_label']\n",
        "        # Simulate predictions (mostly correct with some errors)\n",
        "        if np.random.random() > 0.15:  # 85% accuracy\n",
        "            pred_label = true_label\n",
        "            confidence = np.random.uniform(0.7, 0.95)\n",
        "        else:\n",
        "            pred_label = np.random.choice([l for l in range(4) if l != true_label])\n",
        "            confidence = np.random.uniform(0.5, 0.7)\n",
        "        \n",
        "        results_data.append({\n",
        "            'sample_id': idx,\n",
        "            'model_name': model_name,\n",
        "            'predicted_label': pred_label,\n",
        "            'confidence': round(confidence, 2),\n",
        "            'true_label': true_label\n",
        "        })\n",
        "\n",
        "df_results = pd.DataFrame(results_data)\n",
        "print(f\"Loaded {len(df_results)} prediction results\\n\")\n",
        "print(\"Results by model:\")\n",
        "print(df_results.groupby('model_name').size())\n",
        "print(\"\\nFirst 10 results:\")\n",
        "df_results.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Create MIAO Depression Severity Schema\n",
        "\n",
        "Create the research schema with:\n",
        "- PHQ-9 aligned severity categories\n",
        "- SKOS mappings to SNOMED CT\n",
        "- Proper bibliographic citations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created schema: http://example.org/miao/DepressionSeveritySchema_Research\n",
            "\n",
            "Categories with SNOMED CT mappings:\n",
            "  Level 0 (Minimal): http://example.org/miao/MinimalDepression\n",
            "  Level 1 (Mild): http://example.org/miao/MildDepression\n",
            "  Level 2 (Moderate): http://example.org/miao/ModerateDepression\n",
            "  Level 3 (Severe): http://example.org/miao/SevereDepression\n"
          ]
        }
      ],
      "source": [
        "def create_depression_severity_schema(graph):\n",
        "    \"\"\"\n",
        "    Create ordinal depression severity classification schema in MIAO format\n",
        "    with SKOS mappings to SNOMED CT.\n",
        "    \"\"\"\n",
        "    # Define schema\n",
        "    schema_uri = EX.DepressionSeveritySchema_Research\n",
        "    graph.add((schema_uri, RDF.type, MIAO.MentalIllnessesSchema))\n",
        "    graph.add((schema_uri, DCTERMS.title, \n",
        "               Literal(\"Research schema for depression severity in text\", lang=\"en\")))\n",
        "    graph.add((schema_uri, DCTERMS.description, \n",
        "               Literal(\"Ordinal taxonomy of depression severity (Minimal, Mild, Moderate, Severe) used in social media corpora and text-based computational research on depression detection. Based on PHQ-9 severity thresholds.\", lang=\"en\")))\n",
        "    graph.add((schema_uri, DCTERMS.created, \n",
        "               Literal(\"2025-12-02\", datatype=XSD.date)))\n",
        "    \n",
        "    # Add bibliographic source\n",
        "    graph.add((schema_uri, DCTERMS.source,\n",
        "               Literal(\"Kroenke K, Spitzer RL, Williams JB. The PHQ-9: validity of a brief depression severity measure. J Gen Intern Med. 2001;16(9):606-13.\")))\n",
        "    \n",
        "    # Define categories with PHQ-9 score ranges and SNOMED CT mappings\n",
        "    categories = [\n",
        "        {\n",
        "            'level': 0,\n",
        "            'name': 'MinimalDepression',\n",
        "            'label': 'Minimal Depression',\n",
        "            'title': 'Minimal depression',\n",
        "            'description': 'Minimal or no depressive symptoms. PHQ-9 score range: 0-4. Indicates little to no clinical significance.',\n",
        "            'snomed': None  # No SNOMED mapping for minimal\n",
        "        },\n",
        "        {\n",
        "            'level': 1,\n",
        "            'name': 'MildDepression',\n",
        "            'label': 'Mild Depression',\n",
        "            'title': 'Mild depression',\n",
        "            'description': 'Mild depressive symptoms. PHQ-9 score range: 5-9. May warrant watchful waiting and repeated assessment.',\n",
        "            'snomed': '310495003'  # Mild depression (SNOMED CT)\n",
        "        },\n",
        "        {\n",
        "            'level': 2,\n",
        "            'name': 'ModerateDepression',\n",
        "            'label': 'Moderate Depression',\n",
        "            'title': 'Moderate depression',\n",
        "            'description': 'Moderate depressive symptoms. PHQ-9 score range: 10-14. Warrants treatment plan, considering counseling, follow-up, and/or pharmacotherapy.',\n",
        "            'snomed': '310496002'  # Moderate depression (SNOMED CT)\n",
        "        },\n",
        "        {\n",
        "            'level': 3,\n",
        "            'name': 'SevereDepression',\n",
        "            'label': 'Severe Depression',\n",
        "            'title': 'Severe depression',\n",
        "            'description': 'Severe depressive symptoms. PHQ-9 score range: 15-27 (includes moderately severe 15-19 and severe 20-27). Warrants active treatment with pharmacotherapy and/or psychotherapy.',\n",
        "            'snomed': '310497006'  # Severe depression (SNOMED CT)\n",
        "        }\n",
        "    ]\n",
        "    \n",
        "    category_map = {}\n",
        "    \n",
        "    for cat in categories:\n",
        "        category_uri = EX[cat['name']]\n",
        "        graph.add((category_uri, RDF.type, MIAO.MentalIllnessCategory))\n",
        "        graph.add((category_uri, DCTERMS.title, Literal(cat['title'], lang=\"en\")))\n",
        "        graph.add((category_uri, DCTERMS.description, Literal(cat['description'], lang=\"en\")))\n",
        "        graph.add((category_uri, DCTERMS.identifier, Literal(cat['level'], datatype=XSD.integer)))\n",
        "        graph.add((category_uri, RDFS.label, Literal(cat['label'], lang=\"en\")))\n",
        "        \n",
        "        # Schema relationships\n",
        "        graph.add((category_uri, MIAO.isMentalIllnessCategoryOf, schema_uri))\n",
        "        graph.add((schema_uri, MIAO.hasMentalIllnessCategory, category_uri))\n",
        "        \n",
        "        # Add SKOS mapping to SNOMED CT if available\n",
        "        if cat['snomed']:\n",
        "            snomed_uri = SNOMED[cat['snomed']]\n",
        "            graph.add((category_uri, SKOS.related, snomed_uri))\n",
        "        \n",
        "        category_map[cat['level']] = category_uri\n",
        "    \n",
        "    return schema_uri, category_map\n",
        "\n",
        "schema_uri, category_map = create_depression_severity_schema(g)\n",
        "print(f\"Created schema: {schema_uri}\")\n",
        "print(f\"\\nCategories with SNOMED CT mappings:\")\n",
        "for level, uri in category_map.items():\n",
        "    severity_name = {0: 'Minimal', 1: 'Mild', 2: 'Moderate', 3: 'Severe'}[level]\n",
        "    print(f\"  Level {level} ({severity_name}): {uri}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Model Dataset as MIAO Dataset\n",
        "\n",
        "Create dataset metadata with proper provenance and distribution information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created dataset: http://example.org/miao/Depression_Severity_Dataset\n",
            "\n",
            "Class distribution added to RDF graph\n"
          ]
        }
      ],
      "source": [
        "def create_dataset_metadata(graph, df, dataset_name=\"Depression_Severity_Dataset\"):\n",
        "    \"\"\"\n",
        "    Create MIAO Dataset with complete metadata.\n",
        "    \"\"\"\n",
        "    dataset_uri = EX[dataset_name]\n",
        "    \n",
        "    # Dataset metadata\n",
        "    graph.add((dataset_uri, RDF.type, MIAO.Dataset))\n",
        "    graph.add((dataset_uri, DCTERMS.title, Literal(dataset_name.replace('_', ' '))))\n",
        "    graph.add((dataset_uri, DCTERMS.description, \n",
        "               Literal(f\"Text dataset with {len(df)} samples annotated with depression severity labels (0-3) based on PHQ-9 criteria.\")))\n",
        "    graph.add((dataset_uri, DCTERMS.created, \n",
        "               Literal(datetime.now().strftime(\"%Y-%m-%d\"), datatype=XSD.date)))\n",
        "    \n",
        "    # Statistical properties\n",
        "    graph.add((dataset_uri, MIAO.numberOfSamples, Literal(len(df), datatype=XSD.integer)))\n",
        "    \n",
        "    # Class distribution\n",
        "    for label, count in df['severity_label'].value_counts().items():\n",
        "        dist_uri = EX[f\"{dataset_name}_Distribution_Level{label}\"]\n",
        "        graph.add((dist_uri, RDF.type, MIAO.ClassDistribution))\n",
        "        graph.add((dist_uri, MIAO.hasClass, category_map[label]))\n",
        "        graph.add((dist_uri, MIAO.numberOfInstances, Literal(count, datatype=XSD.integer)))\n",
        "        graph.add((dataset_uri, MIAO.hasClassDistribution, dist_uri))\n",
        "    \n",
        "    # Link to schema\n",
        "    graph.add((dataset_uri, MIAO.usesSchema, schema_uri))\n",
        "    \n",
        "    return dataset_uri\n",
        "\n",
        "dataset_uri = create_dataset_metadata(g, df_dataset)\n",
        "print(f\"Created dataset: {dataset_uri}\")\n",
        "print(f\"\\nClass distribution added to RDF graph\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Model ML Implementations and Models\n",
        "\n",
        "Create ML model metadata with performance metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Model: BERT_Depression_Classifier\n",
            "  URI: http://example.org/miao/BERT_Depression_Classifier\n",
            "  Metrics:\n",
            "    accuracy: 0.9\n",
            "    precision: 0.9375\n",
            "    recall: 0.875\n",
            "    f1_score: 0.881\n",
            "    avg_confidence: 0.796\n",
            "\n",
            "Model: Feature_Framework_Model\n",
            "  URI: http://example.org/miao/Feature_Framework_Model\n",
            "  Metrics:\n",
            "    accuracy: 0.8\n",
            "    precision: 0.8125\n",
            "    recall: 0.7917\n",
            "    f1_score: 0.7893\n",
            "    avg_confidence: 0.742\n"
          ]
        }
      ],
      "source": [
        "def create_ml_implementation(graph, model_name, metrics):\n",
        "    \"\"\"\n",
        "    Create ML Implementation and Model with performance metrics.\n",
        "    \"\"\"\n",
        "    # Implementation\n",
        "    impl_uri = EX[f\"{model_name}_Implementation\"]\n",
        "    graph.add((impl_uri, RDF.type, MLS.Implementation))\n",
        "    graph.add((impl_uri, DCTERMS.title, Literal(model_name.replace('_', ' '))))\n",
        "    \n",
        "    # Model\n",
        "    model_uri = EX[model_name]\n",
        "    graph.add((model_uri, RDF.type, MLS.Model))\n",
        "    graph.add((model_uri, DCTERMS.title, Literal(model_name.replace('_', ' '))))\n",
        "    graph.add((model_uri, MLS.implements, impl_uri))\n",
        "    \n",
        "    # Add metrics\n",
        "    for metric_name, value in metrics.items():\n",
        "        metric_uri = EX[f\"{model_name}_Metric_{metric_name}\"]\n",
        "        graph.add((metric_uri, RDF.type, MLS.ModelPerformance))\n",
        "        graph.add((metric_uri, RDFS.label, Literal(metric_name)))\n",
        "        graph.add((metric_uri, MLS.hasValue, Literal(value, datatype=XSD.float)))\n",
        "        graph.add((model_uri, MLS.hasQuality, metric_uri))\n",
        "    \n",
        "    return model_uri, impl_uri\n",
        "\n",
        "# Calculate metrics for each model\n",
        "model_metadata = {}\n",
        "\n",
        "for model_name in df_results['model_name'].unique():\n",
        "    model_results = df_results[df_results['model_name'] == model_name]\n",
        "    \n",
        "    # Calculate metrics\n",
        "    accuracy = (model_results['predicted_label'] == model_results['true_label']).mean()\n",
        "    avg_confidence = model_results['confidence'].mean()\n",
        "    \n",
        "    # Per-class metrics\n",
        "    from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "    \n",
        "    precision = precision_score(model_results['true_label'], \n",
        "                               model_results['predicted_label'], \n",
        "                               average='macro', zero_division=0)\n",
        "    recall = recall_score(model_results['true_label'], \n",
        "                         model_results['predicted_label'], \n",
        "                         average='macro', zero_division=0)\n",
        "    f1 = f1_score(model_results['true_label'], \n",
        "                 model_results['predicted_label'], \n",
        "                 average='macro', zero_division=0)\n",
        "    \n",
        "    metrics = {\n",
        "        'accuracy': round(accuracy, 4),\n",
        "        'precision': round(precision, 4),\n",
        "        'recall': round(recall, 4),\n",
        "        'f1_score': round(f1, 4),\n",
        "        'avg_confidence': round(avg_confidence, 4)\n",
        "    }\n",
        "    \n",
        "    model_uri, impl_uri = create_ml_implementation(g, model_name, metrics)\n",
        "    model_metadata[model_name] = {\n",
        "        'model_uri': model_uri,\n",
        "        'impl_uri': impl_uri,\n",
        "        'metrics': metrics\n",
        "    }\n",
        "    \n",
        "    print(f\"\\nModel: {model_name}\")\n",
        "    print(f\"  URI: {model_uri}\")\n",
        "    print(f\"  Metrics:\")\n",
        "    for metric, value in metrics.items():\n",
        "        print(f\"    {metric}: {value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Model Detection Runs and Evaluations\n",
        "\n",
        "Create detection run metadata linking models to datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created detection run for BERT_Depression_Classifier: http://example.org/miao/BERT_Depression_Classifier_Run\n",
            "Created detection run for Feature_Framework_Model: http://example.org/miao/Feature_Framework_Model_Run\n"
          ]
        }
      ],
      "source": [
        "def create_detection_run(graph, model_name, schema_uri, dataset_uri, metrics):\n",
        "    \"\"\"\n",
        "    Create DetectionRun with provenance and evaluation metrics.\n",
        "    \"\"\"\n",
        "    run_uri = EX[f\"{model_name}_Run\"]\n",
        "    \n",
        "    graph.add((run_uri, RDF.type, MIAO.DetectionRun))\n",
        "    graph.add((run_uri, DCTERMS.title, \n",
        "               Literal(f\"Depression Detection Run - {model_name.replace('_', ' ')}\")))\n",
        "    graph.add((run_uri, DCTERMS.created, \n",
        "               Literal(datetime.now().strftime(\"%Y-%m-%dT%H:%M:%S\"), datatype=XSD.dateTime)))\n",
        "    \n",
        "    # Link to model, dataset, and schema\n",
        "    graph.add((run_uri, MIAO.usesModel, model_metadata[model_name]['model_uri']))\n",
        "    graph.add((run_uri, MIAO.usesDataset, dataset_uri))\n",
        "    graph.add((run_uri, MIAO.usesSchema, schema_uri))\n",
        "    \n",
        "    # Add evaluation\n",
        "    eval_uri = EX[f\"{model_name}_Evaluation\"]\n",
        "    graph.add((eval_uri, RDF.type, MIAO.Evaluation))\n",
        "    graph.add((eval_uri, DCTERMS.title, \n",
        "               Literal(f\"Evaluation - {model_name.replace('_', ' ')}\")))\n",
        "    \n",
        "    for metric_name, value in metrics.items():\n",
        "        metric_uri = EX[f\"{model_name}_EvalMetric_{metric_name}\"]\n",
        "        graph.add((metric_uri, RDF.type, MIAO.PerformanceMetric))\n",
        "        graph.add((metric_uri, RDFS.label, Literal(metric_name)))\n",
        "        graph.add((metric_uri, MIAO.hasValue, Literal(value, datatype=XSD.float)))\n",
        "        graph.add((eval_uri, MIAO.hasMetric, metric_uri))\n",
        "    \n",
        "    graph.add((run_uri, MIAO.hasEvaluation, eval_uri))\n",
        "    \n",
        "    return run_uri, eval_uri\n",
        "\n",
        "# Create detection runs\n",
        "run_metadata = {}\n",
        "\n",
        "for model_name, meta in model_metadata.items():\n",
        "    run_uri, eval_uri = create_detection_run(g, model_name, schema_uri, dataset_uri, meta['metrics'])\n",
        "    run_metadata[model_name] = {\n",
        "        'run_uri': run_uri,\n",
        "        'eval_uri': eval_uri\n",
        "    }\n",
        "    print(f\"Created detection run for {model_name}: {run_uri}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Model Individual Predictions\n",
        "\n",
        "Create prediction instances for each sample (optional - can be memory intensive for large datasets)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating prediction instances...\n",
            "\n",
            "  BERT_Depression_Classifier: Created 10 prediction instances\n",
            "  Feature_Framework_Model: Created 10 prediction instances\n",
            "\n",
            "Note: Set max_samples=None to include all predictions (may create large graphs)\n"
          ]
        }
      ],
      "source": [
        "def create_predictions(graph, df_results, df_dataset, model_name, max_samples=None):\n",
        "    \"\"\"\n",
        "    Create individual prediction instances.\n",
        "    Set max_samples to limit the number of predictions added (e.g., 50 for testing).\n",
        "    \"\"\"\n",
        "    model_results = df_results[df_results['model_name'] == model_name]\n",
        "    \n",
        "    if max_samples:\n",
        "        model_results = model_results.head(max_samples)\n",
        "    \n",
        "    prediction_count = 0\n",
        "    \n",
        "    for _, row in model_results.iterrows():\n",
        "        sample_id = row['sample_id']\n",
        "        pred_label = row['predicted_label']\n",
        "        confidence = row['confidence']\n",
        "        true_label = row['true_label']\n",
        "        \n",
        "        # Create prediction URI\n",
        "        pred_uri = EX[f\"{model_name}_Prediction_{sample_id}\"]\n",
        "        \n",
        "        graph.add((pred_uri, RDF.type, MIAO.Prediction))\n",
        "        graph.add((pred_uri, MIAO.predictedCategory, category_map[pred_label]))\n",
        "        graph.add((pred_uri, MIAO.confidence, Literal(confidence, datatype=XSD.float)))\n",
        "        graph.add((pred_uri, MIAO.groundTruthCategory, category_map[true_label]))\n",
        "        \n",
        "        # Link to detection run\n",
        "        graph.add((pred_uri, MIAO.fromDetectionRun, run_metadata[model_name]['run_uri']))\n",
        "        \n",
        "        # Link to sample text (optional - creates sample instances)\n",
        "        sample_uri = EX[f\"Sample_{sample_id}\"]\n",
        "        graph.add((sample_uri, RDF.type, MIAO.Sample))\n",
        "        graph.add((sample_uri, DCTERMS.identifier, Literal(sample_id, datatype=XSD.integer)))\n",
        "        \n",
        "        # Add text content (optional - can make graph large)\n",
        "        text_content = df_dataset.iloc[sample_id]['text']\n",
        "        graph.add((sample_uri, DCTERMS.description, Literal(text_content[:200])))  # Truncate long texts\n",
        "        \n",
        "        graph.add((pred_uri, MIAO.forSample, sample_uri))\n",
        "        \n",
        "        prediction_count += 1\n",
        "    \n",
        "    return prediction_count\n",
        "\n",
        "# Create predictions for all models (limited to 50 samples per model for demonstration)\n",
        "print(\"Creating prediction instances...\\n\")\n",
        "\n",
        "for model_name in model_metadata.keys():\n",
        "    count = create_predictions(g, df_results, df_dataset, model_name, max_samples=50)\n",
        "    print(f\"  {model_name}: Created {count} prediction instances\")\n",
        "\n",
        "print(\"\\nNote: Set max_samples=None to include all predictions (may create large graphs)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Export RDF Graph\n",
        "\n",
        "Export the complete knowledge graph in various RDF formats."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RDF Graph Statistics:\n",
            "  Total triples: 316\n",
            "  Namespaces: 34\n",
            "\n",
            "Instances by type:\n",
            "  MentalIllnessesSchema: 1\n",
            "  MentalIllnessCategory: 4\n",
            "  Dataset: 1\n",
            "  Model: 2\n",
            "  DetectionRun: 2\n",
            "  Prediction: 20\n",
            "  Evaluation: 2\n"
          ]
        }
      ],
      "source": [
        "# Print statistics\n",
        "print(\"RDF Graph Statistics:\")\n",
        "print(f\"  Total triples: {len(g)}\")\n",
        "print(f\"  Namespaces: {len(list(g.namespaces()))}\")\n",
        "\n",
        "# Count instances by type\n",
        "print(\"\\nInstances by type:\")\n",
        "for type_uri in [MIAO.MentalIllnessesSchema, MIAO.MentalIllnessCategory, \n",
        "                 MIAO.Dataset, MLS.Model, MIAO.DetectionRun, \n",
        "                 MIAO.Prediction, MIAO.Evaluation]:\n",
        "    count = len(list(g.subjects(RDF.type, type_uri)))\n",
        "    type_name = str(type_uri).split('#')[-1]\n",
        "    if count > 0:\n",
        "        print(f\"  {type_name}: {count}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Exported RDF graph to: depression_detection_miao.ttl\n",
            "Exported RDF/XML to: depression_detection_miao.rdf\n",
            "Exported JSON-LD to: depression_detection_miao.jsonld\n",
            "\n",
            "============================================================\n",
            "First 50 lines of Turtle output:\n",
            "============================================================\n",
            "@prefix dcterms: <http://purl.org/dc/terms/> .\n",
            "@prefix ex: <http://example.org/miao/> .\n",
            "@prefix miao: <https://w3id.org/miao#> .\n",
            "@prefix mls: <http://www.w3.org/ns/mls#> .\n",
            "@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\n",
            "@prefix skos: <http://www.w3.org/2004/02/skos/core#> .\n",
            "@prefix snomed: <http://snomed.info/id/> .\n",
            "@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .\n",
            "\n",
            "ex:BERT_Depression_Classifier_Prediction_0 a miao:Prediction ;\n",
            "    miao:confidence \"0.94\"^^xsd:float ;\n",
            "    miao:forSample ex:Sample_0 ;\n",
            "    miao:fromDetectionRun ex:BERT_Depression_Classifier_Run ;\n",
            "    miao:groundTruthCategory ex:MinimalDepression ;\n",
            "    miao:predictedCategory ex:MinimalDepression .\n",
            "\n",
            "ex:BERT_Depression_Classifier_Prediction_1 a miao:Prediction ;\n",
            "    miao:confidence \"0.85\"^^xsd:float ;\n",
            "    miao:forSample ex:Sample_1 ;\n",
            "    miao:fromDetectionRun ex:BERT_Depression_Classifier_Run ;\n",
            "    miao:groundTruthCategory ex:MildDepression ;\n",
            "    miao:predictedCategory ex:MildDepression .\n",
            "\n",
            "ex:BERT_Depression_Classifier_Prediction_2 a miao:Prediction ;\n",
            "    miao:confidence \"0.74\"^^xsd:float ;\n",
            "    miao:forSample ex:Sample_2 ;\n",
            "    miao:fromDetectionRun ex:BERT_Depression_Classifier_Run ;\n",
            "    miao:groundTruthCategory ex:ModerateDepression ;\n",
            "    miao:predictedCategory ex:ModerateDepression .\n",
            "\n",
            "ex:BERT_Depression_Classifier_Prediction_3 a miao:Prediction ;\n",
            "    miao:confidence \"0.62\"^^xsd:float ;\n",
            "    miao:forSample ex:Sample_3 ;\n",
            "    miao:fromDetectionRun ex:BERT_Depression_Classifier_Run ;\n",
            "    miao:groundTruthCategory ex:SevereDepression ;\n",
            "    miao:predictedCategory ex:MinimalDepression .\n",
            "\n",
            "ex:BERT_Depression_Classifier_Prediction_4 a miao:Prediction ;\n",
            "    miao:confidence \"0.71\"^^xsd:float ;\n",
            "    miao:forSample ex:Sample_4 ;\n",
            "    miao:fromDetectionRun ex:BERT_Depression_Classifier_Run ;\n",
            "    miao:groundTruthCategory ex:MinimalDepression ;\n",
            "    miao:predictedCategory ex:MinimalDepression .\n",
            "\n",
            "ex:BERT_Depression_Classifier_Prediction_5 a miao:Prediction ;\n",
            "    miao:confidence \"0.91\"^^xsd:float ;\n",
            "    miao:forSample ex:Sample_5 ;\n",
            "    miao:fromDetectionRun ex:BERT_Depression_Classifier_Run ;\n",
            "    miao:groundTruthCategory ex:MildDepression ;\n",
            "    miao:predictedCategory ex:MildDepression .\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Export to Turtle format (most readable)\n",
        "output_file_ttl = 'depression_detection_miao.ttl'\n",
        "g.serialize(destination=output_file_ttl, format='turtle')\n",
        "print(f\"\\nExported RDF graph to: {output_file_ttl}\")\n",
        "\n",
        "# Export to other formats\n",
        "g.serialize(destination='depression_detection_miao.rdf', format='xml')\n",
        "print(f\"Exported RDF/XML to: depression_detection_miao.rdf\")\n",
        "\n",
        "g.serialize(destination='depression_detection_miao.jsonld', format='json-ld')\n",
        "print(f\"Exported JSON-LD to: depression_detection_miao.jsonld\")\n",
        "\n",
        "# Display first 50 lines of Turtle output\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"First 50 lines of Turtle output:\")\n",
        "print(\"=\"*60)\n",
        "with open(output_file_ttl, 'r') as f:\n",
        "    lines = f.readlines()[:50]\n",
        "    print(''.join(lines))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Sample SPARQL Queries\n",
        "\n",
        "Demonstrate how to query the RDF knowledge graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Query 1: Model Performance Comparison\n",
            "============================================================\n",
            "BERT_Depression_Classifier               accuracy        0.9000\n",
            "BERT_Depression_Classifier               avg_confidence  0.7960\n",
            "BERT_Depression_Classifier               f1_score        0.8810\n",
            "BERT_Depression_Classifier               precision       0.9375\n",
            "BERT_Depression_Classifier               recall          0.8750\n",
            "Feature_Framework_Model                  accuracy        0.8000\n",
            "Feature_Framework_Model                  avg_confidence  0.7420\n",
            "Feature_Framework_Model                  f1_score        0.7893\n",
            "Feature_Framework_Model                  precision       0.8125\n",
            "Feature_Framework_Model                  recall          0.7917\n"
          ]
        }
      ],
      "source": [
        "# Query 1: Compare model performance\n",
        "query1 = \"\"\"\n",
        "PREFIX miao: <http://www.semanticweb.org/miao#>\n",
        "PREFIX mls: <http://www.w3.org/ns/mls#>\n",
        "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
        "PREFIX dcterms: <http://purl.org/dc/terms/>\n",
        "\n",
        "SELECT ?model ?metric_name ?value\n",
        "WHERE {\n",
        "    ?model a mls:Model ;\n",
        "           dcterms:title ?model_title ;\n",
        "           mls:hasQuality ?metric .\n",
        "    ?metric rdfs:label ?metric_name ;\n",
        "            mls:hasValue ?value .\n",
        "}\n",
        "ORDER BY ?model ?metric_name\n",
        "\"\"\"\n",
        "\n",
        "print(\"Query 1: Model Performance Comparison\")\n",
        "print(\"=\"*60)\n",
        "results1 = g.query(query1)\n",
        "for row in results1:\n",
        "    model_name = str(row.model).split('/')[-1]\n",
        "    print(f\"{model_name:<40} {row.metric_name:<15} {float(row.value):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Query 2: Distribution of Predictions by Severity Level\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Query 2: Distribution of predictions by severity level\n",
        "query2 = \"\"\"\n",
        "PREFIX miao: <http://www.semanticweb.org/miao#>\n",
        "PREFIX dcterms: <http://purl.org/dc/terms/>\n",
        "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
        "\n",
        "SELECT ?category_label (COUNT(?prediction) as ?count)\n",
        "WHERE {\n",
        "    ?prediction a miao:Prediction ;\n",
        "                miao:predictedCategory ?category .\n",
        "    ?category rdfs:label ?category_label .\n",
        "}\n",
        "GROUP BY ?category_label\n",
        "ORDER BY ?category_label\n",
        "\"\"\"\n",
        "\n",
        "print(\"\\n\\nQuery 2: Distribution of Predictions by Severity Level\")\n",
        "print(\"=\"*60)\n",
        "results2 = g.query(query2)\n",
        "for row in results2:\n",
        "    print(f\"{str(row.category_label):<30} {int(row.count):>5} predictions\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Query 3: High Confidence 'Severe Depression' Predictions (confidence > 0.85)\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Query 3: High confidence Severe depression predictions\n",
        "query3 = \"\"\"\n",
        "PREFIX miao: <http://www.semanticweb.org/miao#>\n",
        "PREFIX dcterms: <http://purl.org/dc/terms/>\n",
        "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
        "PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>\n",
        "\n",
        "SELECT ?prediction ?confidence ?sample_text ?is_correct\n",
        "WHERE {\n",
        "    ?prediction a miao:Prediction ;\n",
        "                miao:predictedCategory ?pred_category ;\n",
        "                miao:groundTruthCategory ?true_category ;\n",
        "                miao:confidence ?confidence ;\n",
        "                miao:forSample ?sample .\n",
        "    \n",
        "    ?pred_category rdfs:label \"Severe Depression\"@en .\n",
        "    ?sample dcterms:description ?sample_text .\n",
        "    \n",
        "    BIND(IF(?pred_category = ?true_category, \"\", \"\") AS ?is_correct)\n",
        "    \n",
        "    FILTER(?confidence > 0.85)\n",
        "}\n",
        "ORDER BY DESC(?confidence)\n",
        "LIMIT 5\n",
        "\"\"\"\n",
        "\n",
        "print(\"\\n\\nQuery 3: High Confidence 'Severe Depression' Predictions (confidence > 0.85)\")\n",
        "print(\"=\"*60)\n",
        "results3 = g.query(query3)\n",
        "for i, row in enumerate(results3, 1):\n",
        "    print(f\"\\n{i}. Confidence: {float(row.confidence):.3f} | Correct: {row.is_correct}\")\n",
        "    print(f\"   Text: {str(row.sample_text)[:80]}...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Query 4: Disagreements Between Models (same sample, different predictions)\n",
            "============================================================\n",
            "\n",
            "No disagreements found (or insufficient predictions in graph)\n"
          ]
        }
      ],
      "source": [
        "# Query 4: Compare predictions between models for same samples\n",
        "query4 = \"\"\"\n",
        "PREFIX miao: <http://www.semanticweb.org/miao#>\n",
        "PREFIX dcterms: <http://purl.org/dc/terms/>\n",
        "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
        "\n",
        "SELECT ?sample_id ?model1_pred ?model1_conf ?model2_pred ?model2_conf ?true_label\n",
        "WHERE {\n",
        "    # First model predictions\n",
        "    ?pred1 a miao:Prediction ;\n",
        "           miao:forSample ?sample ;\n",
        "           miao:predictedCategory ?cat1 ;\n",
        "           miao:confidence ?model1_conf ;\n",
        "           miao:fromDetectionRun ?run1 ;\n",
        "           miao:groundTruthCategory ?true_cat .\n",
        "    \n",
        "    # Second model predictions for same sample\n",
        "    ?pred2 a miao:Prediction ;\n",
        "           miao:forSample ?sample ;\n",
        "           miao:predictedCategory ?cat2 ;\n",
        "           miao:confidence ?model2_conf ;\n",
        "           miao:fromDetectionRun ?run2 .\n",
        "    \n",
        "    ?sample dcterms:identifier ?sample_id .\n",
        "    ?cat1 rdfs:label ?model1_pred .\n",
        "    ?cat2 rdfs:label ?model2_pred .\n",
        "    ?true_cat rdfs:label ?true_label .\n",
        "    \n",
        "    # Ensure different models\n",
        "    FILTER(?run1 != ?run2)\n",
        "    \n",
        "    # Only show cases where predictions differ\n",
        "    FILTER(?cat1 != ?cat2)\n",
        "}\n",
        "ORDER BY ?sample_id\n",
        "LIMIT 5\n",
        "\"\"\"\n",
        "\n",
        "print(\"\\n\\nQuery 4: Disagreements Between Models (same sample, different predictions)\")\n",
        "print(\"=\"*60)\n",
        "results4 = g.query(query4)\n",
        "count = 0\n",
        "for row in results4:\n",
        "    count += 1\n",
        "    print(f\"\\nSample {int(row.sample_id)}:\")\n",
        "    print(f\"  Model 1: {str(row.model1_pred):<25} (conf: {float(row.model1_conf):.3f})\")\n",
        "    print(f\"  Model 2: {str(row.model2_pred):<25} (conf: {float(row.model2_conf):.3f})\")\n",
        "    print(f\"  True label: {str(row.true_label)}\")\n",
        "\n",
        "if count == 0:\n",
        "    print(\"\\nNo disagreements found (or insufficient predictions in graph)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Validation Report\n",
        "\n",
        "Validate the RDF graph against MIAO ontology requirements."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "MIAO ONTOLOGY VALIDATION REPORT\n",
            "============================================================\n",
            "\n",
            " Schema has 0 categories (expected: 4)\n",
            " 0 categories have complete metadata (title, description, identifier, label)\n",
            " 0 SKOS mappings to SNOMED CT (expected: 3, excluding Minimal)\n",
            "\n",
            " 2 models with performance metrics:\n",
            "    - BERT_Depression_Classifier: 5 metrics\n",
            "    - Feature_Framework_Model: 5 metrics\n",
            "\n",
            " 0 detection runs properly linked to model, dataset, and schema\n",
            "\n",
            " No predictions found in graph\n",
            "\n",
            " Schema has bibliographic source citation (PHQ-9): False\n",
            "\n",
            "============================================================\n",
            "VALIDATION COMPLETE\n",
            "============================================================\n",
            "\n",
            "Total RDF triples: 316\n",
            "Graph is ready for integration with MIAO knowledge base.\n"
          ]
        }
      ],
      "source": [
        "# Generate validation report\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"MIAO ONTOLOGY VALIDATION REPORT\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Check 1: Schema has categories\n",
        "query_check1 = \"\"\"\n",
        "PREFIX miao: <http://www.semanticweb.org/miao#>\n",
        "SELECT (COUNT(?category) as ?count)\n",
        "WHERE {\n",
        "    ?schema a miao:MentalIllnessesSchema ;\n",
        "            miao:hasMentalIllnessCategory ?category .\n",
        "}\n",
        "\"\"\"\n",
        "result = list(g.query(query_check1))[0]\n",
        "print(f\"\\n Schema has {int(result['count'])} categories (expected: 4)\")\n",
        "\n",
        "# Check 2: All categories have required metadata\n",
        "query_check2 = \"\"\"\n",
        "PREFIX miao: <http://www.semanticweb.org/miao#>\n",
        "PREFIX dcterms: <http://purl.org/dc/terms/>\n",
        "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
        "SELECT ?category\n",
        "WHERE {\n",
        "    ?category a miao:MentalIllnessCategory ;\n",
        "              dcterms:title ?title ;\n",
        "              dcterms:description ?desc ;\n",
        "              dcterms:identifier ?id ;\n",
        "              rdfs:label ?label .\n",
        "}\n",
        "\"\"\"\n",
        "result = list(g.query(query_check2))\n",
        "print(f\" {len(result)} categories have complete metadata (title, description, identifier, label)\")\n",
        "\n",
        "# Check 3: SKOS mappings present\n",
        "query_check3 = \"\"\"\n",
        "PREFIX miao: <http://www.semanticweb.org/miao#>\n",
        "PREFIX skos: <http://www.w3.org/2004/02/skos/core#>\n",
        "SELECT (COUNT(?mapping) as ?count)\n",
        "WHERE {\n",
        "    ?category a miao:MentalIllnessCategory ;\n",
        "              skos:related ?snomed .\n",
        "    BIND(?snomed AS ?mapping)\n",
        "}\n",
        "\"\"\"\n",
        "result = list(g.query(query_check3))[0]\n",
        "print(f\" {int(result['count'])} SKOS mappings to SNOMED CT (expected: 3, excluding Minimal)\")\n",
        "\n",
        "# Check 4: Models have performance metrics\n",
        "query_check4 = \"\"\"\n",
        "PREFIX mls: <http://www.w3.org/ns/mls#>\n",
        "SELECT ?model (COUNT(?metric) as ?metric_count)\n",
        "WHERE {\n",
        "    ?model a mls:Model ;\n",
        "           mls:hasQuality ?metric .\n",
        "}\n",
        "GROUP BY ?model\n",
        "\"\"\"\n",
        "result = list(g.query(query_check4))\n",
        "print(f\"\\n {len(result)} models with performance metrics:\")\n",
        "for row in result:\n",
        "    model_name = str(row.model).split('/')[-1]\n",
        "    print(f\"    - {model_name}: {int(row.metric_count)} metrics\")\n",
        "\n",
        "# Check 5: DetectionRuns link all components\n",
        "query_check5 = \"\"\"\n",
        "PREFIX miao: <http://www.semanticweb.org/miao#>\n",
        "SELECT ?run ?model ?dataset ?schema\n",
        "WHERE {\n",
        "    ?run a miao:DetectionRun ;\n",
        "         miao:usesModel ?model ;\n",
        "         miao:usesDataset ?dataset ;\n",
        "         miao:usesSchema ?schema .\n",
        "}\n",
        "\"\"\"\n",
        "result = list(g.query(query_check5))\n",
        "print(f\"\\n {len(result)} detection runs properly linked to model, dataset, and schema\")\n",
        "\n",
        "# Check 6: Predictions have confidence scores\n",
        "query_check6 = \"\"\"\n",
        "PREFIX miao: <http://www.semanticweb.org/miao#>\n",
        "SELECT (COUNT(?pred) as ?count) (AVG(?conf) as ?avg_conf)\n",
        "WHERE {\n",
        "    ?pred a miao:Prediction ;\n",
        "          miao:confidence ?conf .\n",
        "}\n",
        "\"\"\"\n",
        "result = list(g.query(query_check6))[0]\n",
        "if int(result['count']) > 0:\n",
        "    print(f\"\\n {int(result['count'])} predictions with confidence scores (avg: {float(result.avg_conf):.3f})\")\n",
        "else:\n",
        "    print(f\"\\n No predictions found in graph\")\n",
        "\n",
        "# Check 7: Source citation present\n",
        "query_check7 = \"\"\"\n",
        "PREFIX miao: <http://www.semanticweb.org/miao#>\n",
        "PREFIX dcterms: <http://purl.org/dc/terms/>\n",
        "SELECT ?schema ?source\n",
        "WHERE {\n",
        "    ?schema a miao:MentalIllnessesSchema ;\n",
        "            dcterms:source ?source .\n",
        "}\n",
        "\"\"\"\n",
        "result = list(g.query(query_check7))\n",
        "print(f\"\\n Schema has bibliographic source citation (PHQ-9): {len(result) > 0}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"VALIDATION COMPLETE\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nTotal RDF triples: {len(g)}\")\n",
        "print(\"Graph is ready for integration with MIAO knowledge base.\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "testing",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
